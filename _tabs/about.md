---
# the default layout is 'page'
icon: fas fa-info-circle
order: 4
---

#### 伟大的Aiden

![image.png]({{ site.url }}/source/internal/about.jpg){: .right width="200" height="200" }


- **概况** | `好多年工作经验` | 男 | `2017年12月10日`—`至今` |   `已婚` 
- **教育** | 本科 | 物理学专业 
- **邮箱** | `aiden.dong.private@gmail.com` 
- **地址** | 山东

##### 自我评价

底层搬砖打工人，主要从事数据平台侧能力建设与引擎侧功能优化，为数据平台用户提供简易的数据开发能力与高效的数据计算速度。

##### 能力方面

- 底层工具语言，算法，网络，系统等相对扎实。
- 有过数据平台建设，运维，升级，迁移等经验，对于数据平台把握相对成熟。
-  熟悉阿里云，华为云，Azure,  AWS 等相关云厂商，并做过混合云的数据平台建设。
- 有过数据中台建设经验，对数据中台能力输出与功能建设相对熟悉。
- 对数据湖方面较为熟悉，阅读并优化过产品代码，并应用到平台能力中。
- 对计算引擎方面较为熟悉， 阅读相关产品源码，并深入了解功能优化，为用户提供稳定高效的计算环境。
- 参与 Apache 社区代码贡献。

##### 求职意向

维度 | 说明 |
-- | -- | 
**目标职能** | 数据存储计算引擎，数据平台架构 | 
**期望薪资** | 面议 |
**到岗时间** | 面议 |
**目标地点** | 大厂 | 

##### 项目经验

###### 调度平台建设

建设公司内部离线计算作业调度管理平台，该平台主要为公司广告业务管理计算作业，每天调度任务5w+。
对接数仓业务，DMP, 特征工程，算法任务，总计线上线下9套集群。

主要实现 : `作业统一管理运维`，`作业健康度检测`， `僵尸作业自动下线`，`基于部门的调度资源隔离`，`基于部门的分布式计算资源隔离`

主要工作内容为Azkaban调度系统运维与二开: 

- 优化用户权限管理体系，与公司组织架构+LDAP相结合的认证管理体系
- 优化调度服务策略，实现基于部门的调度资源隔离
- 优化作业执行策略，实现基于部门的分布式计算资源映射关系
- 优化作业管理功能，实现作业健康度检查， 作业预警，无效作业自动下线策略

###### 数据平台建设

负责大数据平台从0到1的基础组件服务与稳定性建设；

建设数据平台PASS服务, 完成基于云资源的数据平台能力建设(对标`AWS EMR`);

功能包括 ： `集群一键化部署`，`服务组件配置管理` , `服务监控`, `弹性伸缩`;

目标意义： `极大降低了运维成本`， `增加集群服务稳定性`， `极大降低了故障恢复时间`，`极大节省了公司成本`;

主要工作内容为 : 

- 深入优化数据平台相关组件性能，包括 `HDFS`, `YARN`, `Hive`, `Spark`; 
- 开发基于SpringBoot的集群管理部署平台，方便用户基于平台一键部署管理集群;
- 深入研究与优化Ambari服务，将Ambari与集群管理平台相结合，在AWS ECS上实现自动化部署，运维，与弹性伸缩功能;
- 优化集群监控相关接口， 完善监控告警能力;

###### 数据中台能力建设-存储侧能力

- 为数据中台引入 `Apache Hudi` 能力， 用来解决用户表`upsert`等相关场景。主要工作内容是封装Hudi相关功能接口， 解决暴露的一些 Bug。从中台侧为用户带来简易的使用体验，用户无需关心底层细节，基于传统经验一键创建与使用hudi表数据。

- 为数据中台引入`Apache Paimon`能力，解决用户在流批一体化的使用场景。主要工作内容为封装paimon到 spark, flink 引擎侧。屏蔽paimon的表细节。为用户支持无感知的使用方式， 用户通过传统SQL 无差异化使用paimon。

- 非结构化数据存储管理；主要工作内容是非结构化数据入湖，生命周期管理， 元信息抽取， embedding计算， 检索服务建设。帮助用户建立完善的非结构化数据管理体系。方便用户对非结构化数据维护，检索，计算能力。


###### 数据中台能力建设-计算侧能力

主要负责离线计算 Spark 能力建设，主要实现接受来自平台的用户SQL计算任务，解析SQL计算逻辑，适配计算集群，优化SQL计算任务， 执行计算逻辑。

优势方面主要有 : `高效执行速度`，`自动适配计算资源`， `故障自动修复`， `风险预感知`。

主要工作内容有 ： 

- 离线计算引擎能力建设，拉通用户SQL解析，计算，状态监控，结果分析全流程。
- RBO功能优化 : 主要涉及对Spark内核优化，增加危险SQL拦截，小文件优化，AQE优化等相关功能。
- HBO优化引擎 : 通过脚本历史运行指标，自动优化该脚本的并行实例数，内存大小，shuffle并行度，写出文件数等。目的是提高计算能力，减少资源消耗
- 补偿优化引擎 : 当用户脚本执行发生错误时，通过补偿优化引擎自动分析错误发生原因，对于非用户逻辑导致的错误，自动修复并重试，用户无感知 

成果方面 ： 每天计算任务包含`5套集群`， `8w+ 计算任务`, `成功率为 99.98%`, 失败任务主要是用户开发SQL语法错误。