---
pin: true
title:      数据中台 | 数据开发概念

date:       2024-09-20
author:     Aiden
image: 
    path : source/internal/post-bg-mma-0.png
categories : ['分布式']
tags : ['数据中台']
--- 

数据开发涉及的产品能力主要包括三个部分，分别是离线开发、实时开发和算法开发。

![image.png]({{ site.url }}/source/nodebook/dataplatform_3_1.png)

- 离线开发主要包括离线数据的加工、发布、运维管理、以及数据分析、数据探索、在线查询和即席分析相关的工作
- 实时开发主要是涉及数据的实时接入和实时处理，简化数据的加工处理过程
- 算法开发主要是提供简单易用的可视化拖拽方式来实现数据价值的深度挖掘

计算能力根据场景可以抽象为四种能力：**批计算、流计算、在线查询和即席分析。** 不同场景配合不同的存储和计算框架来实现，以满足业务的复杂需求。

![image.png]({{ site.url }}/source/nodebook/dataplatform_3_2.png)


| 计算类型 | 适用场景 | 计算框架 | 主要特点 |
| --- | --- | --- | --- |
| 批计算 | 主要用于批量数据的高延时处理场景，如离线数仓的加工、大规模数据的清洗和挖掘等 | MapReduce、Hive、Spark | 数据吞吐量大、延时高，适合人机交互少的场景 |
| 流计算 | 对于数据的加工处理和应用有较强的时效性要求，常见于监控告警场景等 | Flink、SparkSteaming | 低延时，时效性要求高，实时处理 |
| 在线查询 | 主要用于数据结果的在线查询、条件过滤和筛选等，如数据检索、条件过滤等 | 对响应时延要求高的，一般会采用缓存型的存储计算，Redis等；对响应时延要求正常的，可以选择HBASE等；需要进行条件过滤、检索等，可以选择ES、Solr等 | 低延迟，高QPS |
| 即席分析 | 主要用于分析型场景和统计，企业80%的数据处理需求是在线查询和即席分析 | Kylin、Clickhouse、druid等 | 秒级响应，内存计算，任意维度分析 |

### 1. 批计算

传统的数据处理方式通常是将数据导入到专门的数据分析工具中，这样会面临两个问题：

- 源数据非常大时，往往数据的移动就要花费大量的时间
- 传统的数据处理工具往往是单机的，或系统架构无法快速扩容，面对海量数据时，数据处理的时间长

MapReduce是一种分布编程成模型，将一个大规模数据集分解为多个小规模数据集，然后分发给集群中多个节点共同完成计算，这样可以有效降低每一部分的运算复杂度，达到提高运算效率的目的。

![image.png]({{ site.url }}/source/nodebook/dataplatform_3_3.png)

Spark也是一个批量计算框架，它将数据抽象成RDD、DataFrame，这是一种分布式的内存抽象，允许在大型集群上执行基于内存的计算，大大减少了迭代计算所需要的开销。

![image.png]({{ site.url }}/source/nodebook/dataplatform_3_4.png)

离线开发套件封装了大数据相关的技术，包括数据加工、数据分析、在线查询、即席分析等能力，同时也将任务的调度、发布、运维、监控、告警灯进行整合。

将数据汇聚到中台后需要对齐进一步加工处理，企业80%的场景都需要用到离线批处理的能力，这个过程就像一条数据的生产流水线，将采集和汇聚起来的原始数据。通过离线加工的各个环节和相应的数据处理模型，形成有价值的数据资产。

在这个过程中，离线开发套件需要具备的核心功能有：作业调度的策略机制、适配各类异构的数据源、数据权限的管控，通过这些功能来保障数据加工的过程易用可控。

#### 1.作业调度

![image.png]({{ site.url }}/source/nodebook/dataplatform_3_8.png)

在数据开发过程中，经常需要配置作业的依赖关系，作业之间形成一个有向无环图（DAG），同时会配置作业的调度时间以及调度策略。

- **依赖调度：** 所有父作业运行完成后，当前作业才能开始运行， 如图中的作业B必须在作业A和C运行完成后才能开始被调度

- **时间调度：**

指定作业的调度开始时间，如图中的作业B，只有到达0点才能开始被调度

如果一个节点既有父作业又有调度时间约束，那么在调度过程中只有同时满足两种约束条件时才能开始被调度

#### 2. 异构数据源

离线开发针对每种类型的计算引擎都需要开发不同的组件，插件式适配各种数据源，比如针对Hadoop体系分别开发Hive、Spark等插件，用户只需要配置好作业类型，在执行时就可以自动根据作业的类型寻找相应的插件来运行作业。

#### 3. 代码校验

在离线任务的开发过程中，会涉及到各种各样的任务类型。 比如最常见的就是SQL任务，检查器需要做好严格的验证，力争在事前发现问题，避免代码在周期调度的过程中或者运行完成后发现问题。 校验分为语法校验和规则校验：

- **语法校验** 是对SQL的语法进行校验。不同类型的SQL语法是不一样的。
- **规则校验**是指根据规则库提供的规则进行规则校验，比如代码规范校验等

#### 4. 多环境级联

可以通过环境级联的方式灵活支持企业的各类环境需求，方便对资源、权限进行控制和隔离。 

常见的环境如下：

- **单一环境：** 只有一个生产环境，内部管理简单
- **经典环境：** 开发环境中存放脱敏数据，供开发测试使用，上生产走发布流程，用于真实数据生产
- **复杂环境：** 企业有外部人员和内部人员时，会给外部人员提供一个脱敏管控的环境，外部人员开发完的数据模型等经过测试后发布到内部开发环境，由内部检查确认及测试后完成确认发布。

#### 5. 数据权限

由于计算引擎的多样化，数据权限的管理也会面临一些问题：

<1> 部分引擎是拥有独立的权限管理的，导致权限申请需要到每一种引擎上单独操作，使用起来就会变得复杂。同一种计算引擎，不同厂商的权限系统又会不同，比如针对Hadoop自身无权限系统就厂商实现了不同的基于RBAC和PBAC的权限系统。

<2> 数据权限一般是由集群运维人员管理，开发人员无法直接操作，所有的权限都由运维人员开通，会造成运维人员的负担。

<3> 缺乏一套能够同时支持多种计算引擎的权限申请、审批、管理系统。 因此目标就是要构建统一的权限管理系统来支持多种引擎，可以直接在系统上进行各种引擎的权限申请、审批和管理。 适配不同的引擎时，采用插件化的设计思路。

### 2. 流计算

批计算已经能满足多数大数据计算场景，然而要更快捷、高效获取数据中的价值，批计算已经无法满足需求，需要实时处理框架，如Flink、SparkStreaming等来支撑。

![image.png]({{ site.url }}/source/nodebook/dataplatform_3_5.png)

数据的价值在于数据的在线化，随着数据的应用场景越来越丰富，企业对于将数据的价值反馈到业务中的时效性要求也越来越高。 实时开发是对流计算能力的产品封装，通常而言：实时计算具备以下三大特点：

- **实时且无界的数据流：** 实时计算面对的计算是实时的、流式的，流数据是按照时间发生的顺序被实时计算订阅和消费的，并且，由于数据产生的持续性，数据流将长久且持续地集成到实时计算系统中
- **持续且高效的计算：** 实时计算是一种“事件触发”的计算模式，一旦有新的流数据进入实时计算，实时计算立刻发起并进行一次计算任务，因此整个实时计算是持续进行的高效计算
- **流式且实时的数据集成：** 流数据触发一次实时计算的计算结果可以被直接写入目的存储中，例如，将计算后的报表数据直接写入关系型数据库，因此流数据的计算结果可以像流式数据一样持续写入目的存储

基于Flink或者SparkStreaming构建的一站式、高性能实时大数据处理能力，广泛适用于实时ETL、实时报表、监控预警、在线系统等场景。 实时开发涉及的核心功能点包括元数据管理、SQL驱动式开发、组件化配置以及多计算引擎。

#### 1. 元数据管理

与流计算搭配的消息中间件中的数据往往是没有格式约束的，导致后面进行实时计算时无法直接将消息流映射为结构化对象来进行SQL加工。元数据管理可以将Topic中相应的元数据信息统一维护到元数据注册中心，将数据和元数据解耦，Topic中只需要存入数据即可。 在进行流计算时，实时开发会根据Topic自动寻找对应的元数据信息进而形成DataStream，以便进行后续的实时计算。

#### 2. SQL驱动

流计算SQL化可以大大节省开发人员的工作量，提高开发效率，可以将流计算当做动态数据表持续查询，将变动的实时数据（如Kafka中不断推送的消息）、较少变动的维度表（csv文件、MySQL表等）注册为临时视图，同时，加工的中间结果也可以注册为视图，这样在视图上就可以做SQL化的转换处理，最后写入结果表中。

#### 3. 组件化开发

为了更便捷地开发流计算任务， 需要将流计算的输入源、转换逻辑、UDF函数、结果的持久化等封装为组件，开发人员可以通过拖拽相关组件来进行简单的配置和SQL逻辑编写等，将任务具体化为流计算的加工拓扑图，由平台负责任务的调度、解析及运行。



### 3. 在线查询

在线查询需要处理大规模的数据结果集，同时又需要提供一些快速计算的能力，如条件过滤筛选、在线检索等能力，快速从大规模数据中筛选和检索出结果信息，并且支持高并发、低延迟的快速响应。

![image.png]({{ site.url }}/source/nodebook/dataplatform_3_6.png)

### 4. 即席分析

即席分析是指面对大规模的数据集，如何快速进行数据的多维交叉分析，其大部分是聚合型操作，如GroupBy、sum、avg、count等。批计算有足够的灵活性，但耗时比较久，一些传统的关系型数据库以及数仓架构，在一定维度的场景下可以满足响应要求，但数据量受限。

![image.png]({{ site.url }}/source/nodebook/dataplatform_3_7.png)

| 计算能力 | 数据来源类型 | 数据处理方式 | 计算框架 | 时延性 |
| --- | --- | --- | --- | --- |
| 批计算 | 历史数据 | 批处理 | MapReduce Spark | 要求不高 |
| 流计算 | 源源不断的流式数据 | 微批处理或者逐条处理 | Flink  SparkStreaming | 毫秒/秒级延迟 |
| 在线查询 | 历史数据 | 逐条处理或者检索过滤 | ElasticSearch | 毫秒 |
| 即席分析 | 历史数据/近实时数据 | 聚合分析 | Kylin  Druid Clickhouse | 毫秒/秒级延迟 |

### 5. 算法开发

DT时代的数据具有高维稀疏特征，面对百亿甚至千亿样本级别的数据量，对算法处理提出了更高的要求。DT时代的业务具有快速迭代、敏捷开发、灵活试错的特性，新的时代特征为数据智能化发展带来了新的挑战，具体表现在以下几个方面：

- **数据处理难度加大**
- **业务处理要求变高**
- **烟囱式的开发模型**
- **散落各地的模型服务**
- **模型研发环节繁多**
- **冗余分散的基础设施**
- **数据处理/特征工程**
- **多角色企业研发团队**

因此，一款能支持多环境、多集群、多形态模型服务化能力的算法开发工具对企业创新业务、实现数据智能化起着至关重要的作用。

#### 一、算法开发套件

![image.png]({{ site.url }}/source/nodebook/dataplatform_3_9.png)

算法开发作为一站式的企业级机器学习工具，旨在快速赋予企业构建核心算法服务的能力，它集成了以下三种能力、两种建模方式、多种标准化算法组件库。

**三种能力：**

- 以批计算为核心的离线模型训练功能
- 以流计算为核心的在线机器学习
- 基于在线查询、即席分析的数据探索与统计分析能力

**两种建模方式：**

- 可视化建模
- Notebook建模

**多种算法组件：**

- 机器学习计算框架
- 深度学习计算框架
- 其他丰富的标准化组件能力

不同企业的算法应用场景也不一样，数据的差异性也决定了每个企业的算法效果会有很大差别，数据和特征决定了机器学习的上限，比较常见的应用场景如下：

- **金融风控和反欺诈：** 利用关联分析、标签传播、PageRank和社团发现等图算法组件，构建金融反欺诈核心能力，根据客户本身属性和行为数据识别虚假账号和欺诈行为，增强金融监管能力，保障金融业务稳定和安全。
- **文本挖掘分析：** 利用NER、图挖掘等文本算法能力，通过分析非结构化的文本信息自动识别其中的实体以及它们之间的关系，构建关系网，可以深度分析以前未处理的一些线索。
- **广告精准营销：** 通过深入洞察客户需求、偏好和行为，利用PMI等算法组件构建的机器学习模型来挖掘潜在客户。实现可持续的精准营销计划和高质量的曝光率，有效提升广告点击率。
- **个性化推荐：** 利用协同过滤等推荐场景组件，通过分析海量用户行为数据构建多维用户画像，实现千人千面的推荐，提高转化率。

#### 二、算法建模与数据集管理

可视化建模面向算法工程师和数据分析人员，通过拖拽的可视化交互方式便捷编排算法实验，集数据处理、模型训练和评估、在线预测于一体，帮助开发中实现零代码的开发工作。

- **拖拽式实验流：** 通过可视化拖拽，自由编排数据集、模型以及机器学习/深度学习等算法组件，组成有向无环图。
- **丰富算法组件：** 提供大量开箱即用的算法组件，支持用户完成数据处理、模型训练、模型评估和预测的实验流程设计和调试，覆盖主流算法应用场景。
- **实验周期调度：** 在实际智能业务场景中，经常需要根据每天产生的最新数据来定时运行实验和训练算法模型。
- **告警通知：** 算法模型训练时间往往较长，设置告警通知可以保证在第一时间得知实验运行和模型训练的结果。
- **多角色协同：** 算法开发是一个团队型工作，需要很多角色共同参与。

Notebook建模提供了一个集成的Jupyter工具，提供专业算法开发环境和主流算法框架，帮助算法工程师快速、轻松地通过代码开发来构建和训练机器学习模型。

- **JupyterLab在线编程：** 最主流的专业机器学习环境，轻便快捷，支持开发结果查看。 JupyterLab是一个交互式的开发环境，使用它，用户能够以灵活、集成可拓展的方式处理文档和活动。
- **支持通过API方式调用标准算法组件：** 内置大量优化的机器学习算法，高效处理海量数据，提高开发人员的开发效率。
- **支持多语言：** 包括Scala、Python、R、Shell等
- **高可用：** 支持共享存储，实现数据高可用和数据隔离；支持Kubernetes集群，保证服务的高可用和资源隔离。

数据集是算法建模过程中不可或缺的原材料。由于企业业务场景的复杂性，算法开发过程中需要管理并整合不同来源的数据，同时对数据集进行标注和可视化探索，使用数据的使用更高效，简化建模流程。

- **数据接入：** 支持多种类型的数据，主要可分为结构化数据和非结构化数据。提供多种数据接入方式，包括本地上传数据、HDFS数据上传、Kafka数据接入、数据源接入等，可对数据集进行统一管理，并直接在可视化构建实验流时使用。
- **数据标注：** 高质量的数据是模型和算法突破瓶颈的关键因素。通过，数据标准越精准，算法模型训练的效果就越好。支持的数据标注类型包括图片、语音、文本、视频等，通过抽检、多重审核机制把控标注结果的准确性，提升数据输出质量。
- **数据探查：** 数据探查是算法开发人员建模前必不可少的工作。通过数据探查可快速评判数据集的质量和可用性，并根据数据集展现的特点评估使用的模型范围。

#### 三、核心算法组件

为了提高可用性和降低使用门槛，主流机器学习平台都会提供内置的机器学习算法组件，覆盖从数据接入、数据预处理、特征工程、模型训练到平谷和导出的完整算法建模过程，辅助用户高效完成复杂的业务建模。

![image.png]({{ site.url }}/source/nodebook/dataplatform_3_10.png)

##### 1. 数据获取及存储

数据获取及存储组件主要用来从HDFS等存储平台中读取或保存数据和文件，是整个机器学习平台运行的基础。

##### 2. 数据预处理

现实中的大多数数据都是不完整、不一致的，无法直接应用算法，或算法效果不尽人意，因此需要在算法建模和预测之前对数据进行简单处理。数据预处理也是提高数据质量和算法效率的关键因素，常见的组件有随机采样、加权采样、分层采样等。

##### 3. 特征工程

特征工程是指在算法开发过程中，利用特征选择、特征加工、特征降维等技术手段构建对结果具有显著影响或便于模型处理的特征。 利用特征工程相关的组件可以快速构建特征体系、快速选择有效特征，进而大幅度提高算法的质量、提升分析效率。

##### 4. 统计分析

主要用来探索和分析数据特征及其他相关数据的深层统计意义，涵盖相关性分析、分布、参数校验等功能。

##### 5. 机器学习

机器学习是算法开发的核心模块之一，包含主流分类算法、回归算法和聚类算法，可以满足大多数算法需求。

<1> 分类

分类是监督学习领域的一个核心问题，分类用于推测输入数据的类别。当分类的类别为2个时称为二分类问题，当分类的类别为多个时称为多分类问题。

<2> 回归

回归是监督学习领域的一个重要问题，用于预测输入变量和输出变量之间的关系。按输入变量和输出变量之间的关系类型来分，回归可以分为线性回归和非线性回归。

<3> 聚类

聚类是无监督学习研究较多的问题，其目的是将数据分为多个簇，使得簇内的样本较为相似，簇与簇之间样本的差距较大。

##### 6. 深度学习

支持主流的TensorFlow、Caffe等深度学习框架，利用这些组件可以灵活、高效地构建深度学习应用。

##### 7.文本分析

主要包括文本相关的特征处理、模型构建等功能，专门用来实现文本分类、关键词抽取、摘要生成等文本相关应用。

##### 8. 网络分析

提供基于图数据结构的分析组件，这些组件一般用于解决包含网状关系的业务场景，例如金融风控、社群发现、最短路径查找等。

##### 9. 工具类

工具类组件是解决组件间数据格式不一致，以及满足其他额外数据处理需求的一系列组件，是对现有其他功能组件的补充。

#### 四、多算法框架

机器学习涵盖用于分类、回归、聚类、异常检测等。深度学习利用多层神经网络被广泛应用到图像、文本、语音等场景中。

<1> 多算法框架支持

支持主流深度学习和机器学习计算框架，包括TensorFlow、PaddlePaddle、Caffe等。 

- **TensorFlow**
- **PyTorch**
- **LightGBM**

<2> 算法框架多版本支持

实现同一个框架不同版本统一运行，可对不同版本进行统一管理，同时支持机器学习/深度学习计算框架与大数据平台无缝打通，共享存储和计算资源。

多版本实现要支持两种技术：基于Conda的环境隔离和基于Docker的隔离。 前者可以讲不同版本的算法框架打包成不同的Conda环境，支持运行时加载；后者将不同的版本的算法框架打包成不同的镜像，运行时根据需要加载不同的镜像执行，隔离性更好，但会有虚拟化性能的损失。
